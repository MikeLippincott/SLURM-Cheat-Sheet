{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import argparse\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the argument parser\n",
    "parser = argparse.ArgumentParser(description='Slurm stats')\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--acct\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"Path to the slurm accounts file\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--jobs_stats\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"Path to the slurm jobs stats file\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--days\",\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help=\"Number of days to consider\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--user\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"User to consider\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--top_n\",\n",
    "    type=int,\n",
    "    required=False,\n",
    "    default=25,\n",
    "    help=\"Number of top jobs to show\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "acct_file_path = pathlib.Path(args.acct).resolve(strict=True)\n",
    "jobs_file_path = pathlib.Path(args.jobs_stats).resolve(strict=True)\n",
    "days = args.days\n",
    "user = args.user\n",
    "n = args.top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file the first row has the column names and the rest of the rows are the data\n",
    "\n",
    "df = pd.read_csv(acct_file_path, sep='|', header=0, skiprows=1)\n",
    "# drop the columns that are not needed\n",
    "df = df.drop(columns=[\n",
    "    'Cluster',\n",
    "    'Account',\n",
    "    # 'Login',\n",
    "    'TRES Name'\n",
    "    ])\n",
    "\n",
    "# order the data by used\n",
    "df = df.sort_values(by='Used', ascending=False)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# remove NaN values\n",
    "df = df.dropna()\n",
    "# remove 0 values\n",
    "df = df[df.Used != 0]\n",
    "\n",
    "# pretty print the top 15 users and their usage\n",
    "print(f\"Top {n} users by usage for the last {days} days\")\n",
    "print(df.head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the job stats file\n",
    "# sep by tab\n",
    "df = pd.read_csv(jobs_file_path, skiprows=[0,2], sep='\\t', header=0)\n",
    "while \"  \" in df.columns[0]:\n",
    "    df.columns = df.columns.str.replace('  ', ' ')\n",
    "# replace \"  \" in all rows and columns with \" \"\n",
    "df = df.replace('\\s+', ' ', regex=True)\n",
    "# split all the columns\n",
    "new_columns = df.columns[0].split(' ') + ['wait_units']\n",
    "# # # split the contents of the first column\n",
    "df = df[df.columns[0]].str.split(' ', expand=True)\n",
    "# rename the columns\n",
    "df.columns = new_columns\n",
    "# cast types\n",
    "df['jobid'] = df['jobid'].astype(str)\n",
    "df['jobname'] = df['jobname'].astype(str)\n",
    "df['partition'] = df['partition'].astype(str)\n",
    "df['qos'] = df['qos'].astype(str)\n",
    "df['account'] = df['account'].astype(str)\n",
    "df['cpus'] = df['cpus'].astype(int)\n",
    "df['state'] = df['state'].astype(str)\n",
    "df['start-date-time'] = df['start-date-time'].astype(str)\n",
    "df['elapsed'] = df['elapsed'].astype(str)\n",
    "df['wait'] = df['wait'].astype(float)\n",
    "df['wait_units'] = df['wait_units'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total wait time in hours\n",
    "# get summary statistics\n",
    "print(df['wait'].sum())\n",
    "print(f\"{df['wait'].sum()} hours in queue for the last {days} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts for jobs on each partition types\n",
    "print(f\"Job counts by partition for the last {days} days\")\n",
    "print(df['partition'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
