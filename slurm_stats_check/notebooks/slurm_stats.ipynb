{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_file_dir = pathlib.Path(\"../slurm_stats_files\").resolve(strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the argument parser\n",
    "parser = argparse.ArgumentParser(description=\"Slurm stats\")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--acct\", type=str, required=True, help=\"Path to the slurm accounts file\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--jobs_stats\", type=str, required=True, help=\"Path to the slurm jobs stats file\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--days\", type=int, required=True, help=\"Number of days to consider\"\n",
    ")\n",
    "parser.add_argument(\"--user\", type=str, required=True, help=\"User to consider\")\n",
    "parser.add_argument(\n",
    "    \"--top_n\", type=int, required=False, default=25, help=\"Number of top jobs to show\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "acct_file_path = pathlib.Path(stats_file_dir / args.acct).resolve(strict=True)\n",
    "jobs_file_path = pathlib.Path(stats_file_dir / args.jobs_stats).resolve(strict=True)\n",
    "days = args.days\n",
    "user = args.user\n",
    "n = args.top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file the first row has the column names and the rest of the rows are the data\n",
    "\n",
    "df = pd.read_csv(acct_file_path, sep=\"|\", header=0, skiprows=1)\n",
    "# drop the columns that are not needed\n",
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"Cluster\",\n",
    "        \"Account\",\n",
    "        # 'Login',\n",
    "        \"TRES Name\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# order the data by used\n",
    "df = df.sort_values(by=\"Used\", ascending=False)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# remove NaN values\n",
    "df = df.dropna()\n",
    "# remove 0 values\n",
    "df = df[df.Used != 0]\n",
    "\n",
    "# pretty print the top 15 users and their usage\n",
    "print(f\"Top {n} users by usage for the last {days} days\")\n",
    "print(df.head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the job stats file\n",
    "# sep by tab\n",
    "df = pd.read_csv(jobs_file_path, skiprows=[0, 2], sep=\"\\t\", header=0)\n",
    "while \"  \" in df.columns[0]:\n",
    "    df.columns = df.columns.str.replace(\"  \", \" \")\n",
    "    df = df.replace(\"  \", \" \", regex=True)\n",
    "# replace \"  \" in all rows and columns with \" \"\n",
    "\n",
    "# split all the columns\n",
    "new_columns = df.columns[0].split(\" \") + [\"wait_units\"]\n",
    "# # # split the contents of the first column\n",
    "df = df[df.columns[0]].str.split(\" \", expand=True)\n",
    "# rename the columns\n",
    "df.columns = new_columns\n",
    "# cast types\n",
    "df[\"jobid\"] = df[\"jobid\"].astype(str)\n",
    "df[\"jobname\"] = df[\"jobname\"].astype(str)\n",
    "df[\"partition\"] = df[\"partition\"].astype(str)\n",
    "df[\"qos\"] = df[\"qos\"].astype(str)\n",
    "df[\"account\"] = df[\"account\"].astype(str)\n",
    "df[\"cpus\"] = df[\"cpus\"].astype(int)\n",
    "df[\"state\"] = df[\"state\"].astype(str)\n",
    "df[\"start-date-time\"] = df[\"start-date-time\"].astype(str)\n",
    "df[\"elapsed\"] = df[\"elapsed\"].astype(str)\n",
    "df[\"wait\"] = df[\"wait\"].astype(float)\n",
    "df[\"wait_units\"] = df[\"wait_units\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total wait time in hours\n",
    "# get summary statistics\n",
    "print(\n",
    "    f\"{user} has waited a total of {df['wait'].sum()} hours in queue in the last {days} days\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts for jobs on each partition types\n",
    "print(f\"Job counts by partition for the last {days} days\")\n",
    "print(df[\"partition\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
